{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b970351e",
   "metadata": {},
   "source": [
    "   ## NAME- RISHI KUMAR\n",
    "   ## CWID- 20015656"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26797044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "%store -r specificity_test\n",
    "%store -r sensitivity_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06f0dc0",
   "metadata": {},
   "source": [
    "Step 1:\n",
    "use our “titanic” dataset in homework #3, and split data in the same way you did in \n",
    "homework #3 – 80% as training and 20% test sets; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7dab03c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  sex      age  sibsp  survived\n",
       "0       1    1  29.0000      0         1\n",
       "1       1    0   0.9167      1         1\n",
       "2       1    1   2.0000      1         0\n",
       "3       1    0  30.0000      1         0\n",
       "4       1    1  25.0000      1         0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Standardizing values \n",
    "df_main = pd.read_csv(r'C:\\Users\\Rishi\\Downloads\\HW3-1\\Titanic.csv')\n",
    "df_main = df_main[['pclass', 'sex', 'age','sibsp','survived']] \n",
    "df_main['pclass'] = df_main['pclass'].map({'1st':1,'2nd':2,'3rd':3})\n",
    "df_main['sex'] = df_main['sex'].map({'male':0,'female':1})\n",
    "df_main['age'].fillna((df_main['age'].mean()),inplace=True)\n",
    "df_main= df_main.dropna()\n",
    "df_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32097441",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Split\n",
    "attribute = df_main.drop('survived',axis=1)\n",
    "target = df_main['survived']\n",
    "attribute_train, attribute_test, target_train, target_test = train_test_split(attribute, target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39914b4",
   "metadata": {},
   "source": [
    "Step 2:\n",
    "Fit a neural network using independent variables ‘pclass + sex + age + sibsp’ and \n",
    "dependent variable ‘survived’. Fill in n/a attributes with the average of the same attributes \n",
    "from other training examples. Use 2 hidden layers and set the activation functions for both the \n",
    "hidden and output layer to be the sigmoid function. Set “solver” parameter as either SGD \n",
    "(stochastic gradient descend) or Adam (similar to SGD but optimized performance with mini \n",
    "batches). You can adjust parameter “alpha” for regularization (to control overfitting) and other \n",
    "parameters such as “learning rate” and “momentum” as needed.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b49978d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8206106870229007"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#STEP 2 NN with 2 Layers\n",
    "classifier = MLPClassifier(solver='adam',hidden_layer_sizes=(10,15),activation='logistic',learning_rate='constant',learning_rate_init=0.12,alpha=0.00000003, momentum=0.54)\n",
    "classifier = classifier.fit(attribute_train, target_train)\n",
    "pred_2 = classifier.predict(attribute_test)\n",
    "accuracy_score(target_test, pred_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfddd54",
   "metadata": {},
   "source": [
    "Step3:\n",
    "Check the performance of the model with out-of- sample accuracy, defined as      \n",
    "out-of-sample percent survivors correctly predicted (on test set)  \n",
    "out-of-sample percent fatalities correctly predicted (on test set)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46979ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " percent survivors correctly predicted (on testing set) : 67.29%\n",
      "\n",
      " percent fatalities correctly predicted (on testing set) : 92.26%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#report for 2 HL\n",
    "conf_matrix = confusion_matrix(target_test, pred_2)\n",
    "TN = conf_matrix[0][0]\n",
    "FN = conf_matrix[1][0]\n",
    "TP = conf_matrix[1][1]\n",
    "FP = conf_matrix[0][1]\n",
    "sensitivity_test_2 = TP/(TP+FN)\n",
    "specificity_test_2 = TN/(FP+TN)\n",
    "\n",
    "print(\" percent survivors correctly predicted (on testing set) : {0:.2f}%\\n\".format(sensitivity_test_2*100))\n",
    "print(\" percent fatalities correctly predicted (on testing set) : {0:.2f}%\\n\".format(specificity_test_2*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45be5b0d",
   "metadata": {},
   "source": [
    "Please try two different network structures (i.e., number of neurons at each hidden layer) and show their respective accuracy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bad36b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8053435114503816"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#WITH 5 HIDDEN LAYERS\n",
    "classifier_5 = MLPClassifier(solver='adam',hidden_layer_sizes=(10,10,10,25,10),activation='logistic',learning_rate='constant',\n",
    "                           learning_rate_init=0.006,alpha=0.00000071, momentum=0.8)\n",
    "classifier_5 = classifier_5.fit(attribute_train, target_train)\n",
    "\n",
    "pred_5 = classifier_5.predict(attribute_test)\n",
    "\n",
    "accuracy_score(target_test, pred_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c684d6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percent survivors correctly predicted (on testing set) : 63.55%\n",
      "\n",
      "percent fatalities correctly predicted (on testing set) : 92.26%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#report for 50 HL\n",
    "conf_matrix = confusion_matrix(target_test, pred_5)\n",
    "TN = conf_matrix[0][0]\n",
    "FN = conf_matrix[1][0]\n",
    "TP = conf_matrix[1][1]\n",
    "FP = conf_matrix[0][1]\n",
    "sensitivity_test_5 = TP/(TP+FN)\n",
    "specificity_test_5 = TN/(FP+TN)\n",
    "\n",
    "print(\"percent survivors correctly predicted (on testing set) : {0:.2f}%\\n\".format(sensitivity_test_5*100))\n",
    "print(\"percent fatalities correctly predicted (on testing set) : {0:.2f}%\\n\".format(specificity_test_5*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dff2074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8091603053435115"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#WITH 4 HIDDEN LAYERS\n",
    "classifier_4 = MLPClassifier(solver='adam',hidden_layer_sizes=(10,10,10,10),activation='logistic',learning_rate='constant',learning_rate_init=0.012,alpha=0.00000541, momentum=0.54)\n",
    "classifier_4 = classifier_4.fit(attribute_train, target_train)\n",
    "\n",
    "pred_4 = classifier_4.predict(attribute_test)\n",
    "\n",
    "accuracy_score(target_test, pred_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8fb260a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percent survivors correctly predicted (on testing set) : 70.09%\n",
      "\n",
      "percent fatalities correctly predicted (on testing set) : 88.39%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#report for 4 HL\n",
    "conf_matrix = confusion_matrix(target_test, pred_4)\n",
    "TN = conf_matrix[0][0]\n",
    "FN = conf_matrix[1][0]\n",
    "TP = conf_matrix[1][1]\n",
    "FP = conf_matrix[0][1]\n",
    "sensitivity_test_4 = TP/(TP+FN)\n",
    "specificity_test_4 = TN/(FP+TN)\n",
    "\n",
    "print(\"percent survivors correctly predicted (on testing set) : {0:.2f}%\\n\".format(sensitivity_test_4*100))\n",
    "print(\"percent fatalities correctly predicted (on testing set) : {0:.2f}%\\n\".format(specificity_test_4*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e699732",
   "metadata": {},
   "source": [
    "step 4:\n",
    "Compare the out-of-sample accuracy (as defined in step 3) with the random forest \n",
    "obtained in homework #3. (You can either use a table or plot the results of the two algorithms \n",
    "in one figure). Explain any difference in accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a1108d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter</th>\n",
       "      <th>Random forest</th>\n",
       "      <th>2 HL NN</th>\n",
       "      <th>5 HL NN</th>\n",
       "      <th>4 HL NN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>percent survivors correctly predicted (on testing set)</td>\n",
       "      <td>60.784314</td>\n",
       "      <td>67.28972</td>\n",
       "      <td>63.551402</td>\n",
       "      <td>70.093458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>percent fatalities correctly predicted (on testing set)</td>\n",
       "      <td>90.0</td>\n",
       "      <td>92.258065</td>\n",
       "      <td>92.258065</td>\n",
       "      <td>88.387097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Parameter Random forest  \\\n",
       "0   percent survivors correctly predicted (on testing set)   60.784314      \n",
       "1   percent fatalities correctly predicted (on testing set)  90.0           \n",
       "\n",
       "     2 HL NN    5 HL NN    4 HL NN  \n",
       "0  67.28972   63.551402  70.093458  \n",
       "1  92.258065  92.258065  88.387097  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accessing random forest accuracy variables using (%store -r) function \n",
    "\n",
    "\n",
    "df = pd.DataFrame(columns=['Parameter', 'Random forest', '2 HL NN','5 HL NN','4 HL NN'])\n",
    "\n",
    "df = df.append({'Parameter': ' percent survivors correctly predicted (on testing set)', 'Random forest': sensitivity_test*100 , '2 HL NN': sensitivity_test_2*100,'5 HL NN':sensitivity_test_5*100,'4 HL NN':sensitivity_test_4*100}, ignore_index=True)\n",
    "df = df.append({'Parameter': ' percent fatalities correctly predicted (on testing set)', 'Random forest': specificity_test*100 , '2 HL NN': specificity_test_2*100,'5 HL NN':specificity_test_5*100,'4 HL NN':specificity_test_4*100}, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a2bce5",
   "metadata": {},
   "source": [
    "From the above table it is evident that Neural network has better accuracy\n",
    "It appears we get the best results when we take 4 layers and and the accuracy for survivors and fatalities drop after 5 layers \n",
    "we get better results in neural network because of backpropogation and the accuracy drops after 4 layers because of overfitting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
